{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = pd.read_csv('truthvalue.csv', dtype=object)\n",
    "\n",
    "df_truth = df_truth.append(df_truth,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################   attribute reshuffling  ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = df_truth.drop(df_truth.columns[[9, 10, 11, 12, 13, 14, 15, 16 ]], axis=1)\n",
    "df_truth['label'] = 1\n",
    "df_truth_attribute_mixed = df_truth.sample(n=500, axis=0)\n",
    "df_subtract = df_truth[~df_truth.isin(df_truth_attribute_mixed)].dropna()\n",
    "df_truth_attribute_mixed['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(500):\n",
    "    for i in range (2):\n",
    "        random_cell_1 = random.randint(0,8)\n",
    "        random_cell_2 = random.randint(0,8)\n",
    "        if random_cell_1 != random_cell_2:\n",
    "            temp = df_truth_attribute_mixed.iloc[row,random_cell_1]\n",
    "            df_truth_attribute_mixed.iloc[row,random_cell_1] = df_truth_attribute_mixed.iloc[row,random_cell_2]\n",
    "            df_truth_attribute_mixed.iloc[row,random_cell_2] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attribute_shuffled = pd.concat([df_subtract, df_truth_attribute_mixed])\n",
    "df_attribute_shuffled = df_attribute_shuffled.sample(frac=1).reset_index(drop=True)\n",
    "df_attribute_shuffled.to_csv('lstm_dataset_attribute_shuffled.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################   Introduce NaN values  ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = pd.read_csv('truthvalue.csv', dtype=object)\n",
    "df_truth = df_truth.drop(df_truth.columns[[9, 10, 11, 12, 13, 14, 15, 16 ]], axis=1)\n",
    "df_truth['label'] = 1\n",
    "df_truth_none_introduced = df_truth.sample(n=500, axis=0)\n",
    "df_subtract = df_truth[~df_truth.isin(df_truth_none_introduced)].dropna()\n",
    "df_truth_none_introduced['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(500):\n",
    "    random_cell_1 = random.randint(0,8)\n",
    "    df_truth_none_introduced.iloc[row,random_cell_1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth_none_cells = pd.concat([df_subtract, df_truth_none_introduced])\n",
    "df_truth_none_cells = df_truth_none_cells.sample(frac=1).reset_index(drop=True)\n",
    "df_truth_none_cells.to_csv('lstm_dataset_Nan_introduced.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################   Introduce erroneous values  ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = pd.read_csv('truthvalue.csv', dtype=object)\n",
    "df_hospital = pd.read_csv('dirty_data_transformed.csv', dtype=object)\n",
    "df_hospital = df_hospital.drop(df_hospital.columns[[3,4]], axis=1)\n",
    "\n",
    "df_truth['label'] = 1\n",
    "df_hospital['label'] = 1\n",
    "\n",
    "df_truth = df_truth.drop(df_truth.columns[[9, 10, 11, 12, 13, 14, 15, 16 ]], axis=1)\n",
    "df_hospital = df_hospital.drop(df_hospital.columns[[9, 10, 11, 12, 13, 14, 15, 16 ]], axis=1)\n",
    "\n",
    "provider = df_truth['ProviderNumber'].tolist()\n",
    "hospital = df_truth['HospitalName'].tolist()\n",
    "address = df_truth['Address1'].tolist()\n",
    "city = df_truth['City'].tolist()\n",
    "state = df_truth['State'].tolist()\n",
    "zipcode = df_truth['ZipCode'].tolist()\n",
    "county = df_truth['CountyName'].tolist()\n",
    "phone = df_truth['PhoneNumber'].tolist()\n",
    "hospType = df_truth['HospitalType'].tolist()\n",
    "\n",
    "combined_hosp = list(zip(provider, hospital, address, city, state, zipcode, county, phone,hospType))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hospital dirty dataset; maintain dirty dataset separately\n",
    "provider = df_hospital['ProviderNumber'].tolist()\n",
    "hospital = df_hospital['HospitalName'].tolist()\n",
    "address = df_hospital['Address1'].tolist()\n",
    "city = df_hospital['City'].tolist()\n",
    "state = df_hospital['State'].tolist()\n",
    "zipcode = df_hospital['ZipCode'].tolist()\n",
    "county = df_hospital['CountyName'].tolist()\n",
    "phone = df_hospital['PhoneNumber'].tolist()\n",
    "hospType = df_hospital['HospitalType'].tolist()\n",
    "\n",
    "\n",
    "combined_dirty = list(zip(provider, hospital, address, city, state, zipcode, county, phone, hospType))\n",
    "len(combined_dirty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('10001', 'SOUTHEAST ALABAMA MEDICAL CENTER', '1108 ROSS CLARK CIRCLE', 'DOTHAN', 'AL', '36302', 'HOUSTON', '3347938701', 'Acute Care Hospitals')\n",
      "('10001', 'SOUTHEAST ALABAMA MEDICAL CENTER', '1108 ROSS CLARK CIRCLE', 'DOTHAN', 'xL', '36302', 'HOUSTON', '3347938701', 'Acute Care Hospitals')\n"
     ]
    }
   ],
   "source": [
    "print(combined_hosp[42])\n",
    "print(combined_dirty[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating error or dirty cells\n",
    "\n",
    "for i in range(len(combined_dirty)):\n",
    "    for j in range(len(combined_dirty[0])):\n",
    "        flag = False\n",
    "        if combined_dirty[i][j] != combined_hosp[i][j]:\n",
    "            flag = True\n",
    "    if flag == True:    \n",
    "        df_hospital.iloc[i,9] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hospital = df_hospital.sample(frac=1).reset_index(drop=True)\n",
    "df_hospital.to_csv('lstm_dataset_errenous.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### generating 2000 tuples for LSTM ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_truth = pd.read_csv('truthvalue.csv', dtype=object)\n",
    "df_truth = df_truth.append(df_truth,ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop few columns\n",
    "df_truth = df_truth.drop(df_truth.columns[[9,10, 11, 12, 13, 14, 15, 16 ]], axis=1)\n",
    "df_truth['label'] = 1\n",
    "\n",
    "truth_rows = df_truth.shape[0]\n",
    "frac = (int)(truth_rows/2)\n",
    "\n",
    "df_false = df_truth.sample(n = frac, axis=0)\n",
    "\n",
    "df_truth = df_truth[~df_truth.isin(df_false)].dropna()\n",
    "df_false['label'] = 0\n",
    "\n",
    "\n",
    "rows = df_false.shape[0]\n",
    "columns = df_false.shape[1] - 1\n",
    "\n",
    "diff = math.ceil(rows/columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_df = []\n",
    "\n",
    "\n",
    "def sampler(rows, columns, df):\n",
    "    diff = math.ceil(rows/columns)\n",
    "    print (diff)\n",
    "    for i in range(columns):\n",
    "        #check the remaining samples row count, if it lesser than the sample size. terminate by appending the remaining values.\n",
    "        df_row_count = df.shape[0]\n",
    "        if df_row_count < diff:\n",
    "            list_of_df.append(df)\n",
    "        else:\n",
    "            df_sample = df.sample(diff, axis=0)\n",
    "            list_of_df.append(df_sample)\n",
    "            df = df[~df.isin(df_sample)].dropna()          \n",
    "    return list_of_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "#sample the false dataset into different tuples groups\n",
    "#each group will have one column with shuffled values\n",
    "\n",
    "y = sampler(rows, columns, df_false)\n",
    "\n",
    "\n",
    "for idx, val in enumerate(y):\n",
    "    p = shuffle(y[idx].iloc[:,idx].values)\n",
    "    y[idx].iloc[:,idx] = p\n",
    "    \n",
    "df_false = pd.concat(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "rows = df_false.shape[0]\n",
    "columns = df_false.shape[1] - 1\n",
    "\n",
    "def introduce_NAN(percentage,rows,columns,df):\n",
    "    iter = (int)((percentage/100)*rows)\n",
    "    print (iter)\n",
    "    for row in range(iter):\n",
    "        random_cell_1 = random.randint(0,columns-1)\n",
    "        df.iloc[row,random_cell_1] = np.nan\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "#if it is a string add a XX appended in the end.\n",
    "def introduce_error(percentage,rows,columns,df):\n",
    "    iter = (int)((percentage/100)*rows)\n",
    "    for row in range(iter):\n",
    "        random_cell_1 = random.randint(0,columns-1)\n",
    "        orig = df.iloc[row,random_cell_1]\n",
    "        if df.iloc[row,random_cell_1] is not None:\n",
    "            if isinstance(df.iloc[row,random_cell_1], int):\n",
    "                #print (df.iloc[row,random_cell_1])\n",
    "                temp = int(df.iloc[row,random_cell_1]) + random.randint(1,1000)\n",
    "                df.iloc[row,random_cell_1] = temp  \n",
    "            elif isinstance(df.iloc[row,random_cell_1], float):\n",
    "                #print (df.iloc[row,random_cell_1])\n",
    "                temp = int(df.iloc[row,random_cell_1]) + random.rand(1,1000)\n",
    "                df.iloc[row,random_cell_1] = temp \n",
    "            else:\n",
    "                #print (df.iloc[row,random_cell_1])\n",
    "                #str_len = len(str(df.iloc[row,random_cell_1]))\n",
    "                #df.iloc[row,random_cell_1][random.randint(0,str_len)] = x\n",
    "                df.iloc[row,random_cell_1] =  df.iloc[row,random_cell_1] + 'XX'          \n",
    "        \n",
    "        #print (orig,df.iloc[row,random_cell_1])\n",
    "    return df\n",
    "        \n",
    "#input - first parameter - percentage of none values to be introduced\n",
    "#second - row count, third - column count, fourth parameter  = df itself.\n",
    "df_false = introduce_error(5,rows, columns, df_false)\n",
    "df_false = introduce_NAN(5,rows, columns, df_false)\n",
    "\n",
    "frames = [df_truth, df_false]\n",
    "\n",
    "df_final = pd.concat(frames)\n",
    "df_final = df_final.sample(frac=1).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('final.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
